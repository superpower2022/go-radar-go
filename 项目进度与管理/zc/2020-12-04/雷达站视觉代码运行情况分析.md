## 雷达站视觉代码运行情况分析

近期使用训练的模型以及代码进行了一些测试与对比

### CPU版本

我在实验室的CPU情况

```shell
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              48
On-line CPU(s) list: 0-47
Thread(s) per core:  2
Model name:          Intel(R) Xeon(R) CPU E5-2673 v3 @ 2.40GHz
```

使用CPU运行时，每一帧处理时间大概在0.13s左右

运行效果图

![](https://img-blog.csdnimg.cn/20201203145215138.png)

### GPU版本

使用GPU版本需要修改一下代码，之前是没有将权重(weight)放置在GPU上，导致模型在GPU，而权重不在GPU，报错

```shell
RuntimeError: Input type (torch.cuda.HalfTensor) and weight type (torch.HalfTensor) should be the same
```

需要修改一下yolo中的`experimental.py`文件，该文件在目录树位置

```shell
/
├─configs
├─data
├─deep_sort
├─docs
├─models
├─pnp
├─tools
├─yolov5
│  ├─models
│  │  ├─experimental.py
│  ├─utils
│  └─weights
```

需要更改的代码如下

```python
def attempt_load(weights, map_location=None):
    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a
	...
    model.append(torch.load(weights, map_location=map_location)['model'].float().fuse().eval())  # load FP32 model
	...
```

即`torch.load(weights, map_location=map_location)`，需要将`map_location`设置为传入的device，即可将权重加载至GPU上

之后修改`demo.py`文件的`device_ = '0'`，数字为想要选择的GPU序号，通过`nvidia-smi`查看并选择。目前只能**单卡**运行

运行在GPU: 1080Ti上后，每一帧处理时间变为0.054s左右

运行效果图

![](https://img-blog.csdnimg.cn/20201203145215157.png)

显卡的提升效果还是显著的，不过需要优化图形显示部分的代码。

### 分析代码效率

我通过设置4个时间点，来统计每一个关键步骤耗时情况

```python
########################计时 核心过程！########################
t1 = torch_utils.time_synchronized()
#yolo目标检测
bbox_xcycwh, cls_conf, cls_ids = detectPerFrame(im0s)
t2 = torch_utils.time_synchronized()
print('yolo:', t2 - t1, "s")

#目标跟踪 output = [x1,y1,x2,y2,track_id]
outputs,bbox_vxvy = my_deepsort.update(bbox_xcycwh, cls_conf, im0s)
t3 = torch_utils.time_synchronized()
print('deep:', t3 - t2, "s")
#############################################################

########################计算每个装甲板的位姿信息########################
if len(outputs) > 0:
    bbox_tlwh = []
    bbox_xyxy = outputs[:, :4]
    identities = outputs[:, 4]
    #得到角点信息
    bbox_clockwise = getCornerPoints(bbox_xyxy)
    #计算每个目标的偏转角度与距离
    tvec, angels, distance = get3Dposition(bbox_clockwise)
    #############################################################

    armor_color = getArmorColor(im0s, bbox_xyxy)
    bbox_xyxy_show = []
    bbox_vxvy_show = []

    ########################对于每个目标进行可视化########################

    #准备好所有位置和速度标注
    for i in range(len(outputs)):
        #打印出具体位置
        bbox_show = []
        #打印出运动状态（根据kalmanfilter得到的速度）
        motion_show = []
        bbox_vxvy_len = len(bbox_vxvy[0])
        for j in range(len(bbox_xyxy[i])):
            bbox_show.append(bbox_xyxy[i, j]*resize_ratio)
            if j < bbox_vxvy_len :
                motion_show.append(bbox_vxvy[i, j]*resize_ratio)
                bbox_xyxy_show.append(bbox_show)
                bbox_vxvy_show.append(motion_show)

                #打印到相机图
                for_show = cv2.resize(im0s, (show_width, show_height))
                for_show = draw_boxes(for_show, bbox_xyxy_show, angels, distance, tvec, identities)

                #在小地图上显示
                center = getRectCenterpoint(bbox_xyxy_show)
                cur_pic = showLittleMap(lm, center, bbox_vxvy_show,identities,armor_color)
                #############################################################
                t4 = torch_utils.time_synchronized()
                print('show:', t4 - t3, "s")
```

运行结果

![](https://img-blog.csdnimg.cn/20201203145214253.jpg)

并且在原版yolov5上运行其他模型，耗时也是0.012s左右，所以模型应该是没有很大问题

### 展望

考虑着手准备优化图形显示的部分代码，例如通过**线程**之类的操作减少循环堵塞

